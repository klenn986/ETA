{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wso0f_Smc4ee",
    "toc-hr-collapsed": true
   },
   "source": [
    "# Synpsis\n",
    "\n",
    "We import a collection of nineteenth century novels from a variety of authors. \n",
    "The directory consists of files for each section (chapter) of the novels. Each filename contains the following metadata: `author_title_chapter_genre`. \n",
    "\n",
    "The novels are grouped into three genres: `g` for Gothic, `d` for Detective, and `nh` for unclassified (not sure what the abbreviation is for). \n",
    "\n",
    "We can use HCA and PCA to figure out which genre the unclassified sections of text belong to. We can also explore the relationships among the various novels, to see if they fit neatly into their categories.\n",
    "\n",
    "We write a corpus importer as we have done before, but this time need to add levels to our OHCO to include genre, author, and title. \n",
    "\n",
    "Note that we are going through the \"ritual\" of importing the content into our standard format as if we needed all the information we are collection, e.g. POS. For today's exercise, however, we are not going to need this information."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SEDIrQRJc-nn"
   },
   "source": [
    "# Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "477MrZfFc9oh"
   },
   "outputs": [],
   "source": [
    "source_dir = 'vierthaler-stylometry/corpus'\n",
    "para_pat = r'\\n\\n+'\n",
    "token_pat = r'([\\W_]+)'\n",
    "db_file = '../../data/novels.db'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "477MrZfFc9oh"
   },
   "outputs": [],
   "source": [
    "extra_stopwords = \"\"\"\n",
    "us rest went least would much must long one like much say well without though yet might still upon\n",
    "done every rather particular made many previous always never thy thou go first oh thee ere ye came\n",
    "almost could may sometimes seem called among another also however nevertheless even way one two three\n",
    "ever put\n",
    "\"\"\".strip().split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "477MrZfFc9oh"
   },
   "outputs": [],
   "source": [
    "OHCO = ['genre', 'author', 'book', 'chapter', 'para_num', 'sent_num', 'token_num']\n",
    "GENRE = OHCO[:1]\n",
    "AUTHS = OHCO[:2]\n",
    "BOOKS = OHCO[:3]\n",
    "CHAPS = OHCO[:4]\n",
    "PARAS = OHCO[:5]\n",
    "SENTS = OHCO[:6]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "A58rgKXydL8y"
   },
   "source": [
    "# Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 228
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 8617,
     "status": "ok",
     "timestamp": 1550542848134,
     "user": {
      "displayName": "Rafael Alvarado",
      "photoUrl": "https://lh3.googleusercontent.com/-gvKWs7zR4JY/AAAAAAAAAAI/AAAAAAABqfk/Q8O12g6M_T4/s64/photo.jpg",
      "userId": "11010075019714369526"
     },
     "user_tz": 300
    },
    "id": "YbadDvzWW0Sw",
    "outputId": "53c6fd6b-67cf-47cd-e43c-e46a8a334340"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/rca2t/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /Users/rca2t/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package stopwords to /Users/rca2t/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package tagsets to /Users/rca2t/nltk_data...\n",
      "[nltk_data]   Package tagsets is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /Users/rca2t/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import re\n",
    "# import os\n",
    "import glob\n",
    "import sqlite3\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import nltk\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('tagsets')\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "eC-m8q8Hd1dq"
   },
   "source": [
    "# Pragmas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "eC-m8q8Hd1dq"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "AwIc1D23UuOQ",
    "toc-hr-collapsed": false
   },
   "source": [
    "# Process\n",
    "\n",
    "We pause to look at the revised form of our text import function. The parsing function has been replaced with NLTK, which has improved the results of POS tagging. However, this has required some added string manipulation to produce better tokens."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2Oxgp19ejZmU"
   },
   "source": [
    "## Import files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2Oxgp19ejZmU"
   },
   "outputs": [],
   "source": [
    "files = glob.glob(\"{}/*.txt\".format(source_dir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2Oxgp19ejZmU"
   },
   "outputs": [],
   "source": [
    "codes = [f.replace('.txt','').split('/')[-1].split('_') for f in files]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2Oxgp19ejZmU"
   },
   "outputs": [],
   "source": [
    "T = pd.DataFrame(codes, columns = ['author','book','chapter', 'genre'])\n",
    "T = T[CHAPS]\n",
    "T.chapter = T.chapter.astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2Oxgp19ejZmU"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>genre</th>\n",
       "      <th>author</th>\n",
       "      <th>book</th>\n",
       "      <th>chapter</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>d</td>\n",
       "      <td>christie</td>\n",
       "      <td>secretadversary</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>g</td>\n",
       "      <td>austen</td>\n",
       "      <td>northangerabbey</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>d</td>\n",
       "      <td>doyle</td>\n",
       "      <td>scarlet</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>g</td>\n",
       "      <td>shelley</td>\n",
       "      <td>frankenstein</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>d</td>\n",
       "      <td>collins</td>\n",
       "      <td>moonstone</td>\n",
       "      <td>86</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  genre    author             book  chapter\n",
       "0     d  christie  secretadversary       23\n",
       "1     g    austen  northangerabbey       30\n",
       "2     d     doyle          scarlet        5\n",
       "3     g   shelley     frankenstein       37\n",
       "4     d   collins        moonstone       86"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "T.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2Oxgp19ejZmU"
   },
   "outputs": [],
   "source": [
    "T['text'] = [open(f, 'r', encoding='utf-8').read() for f in files]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2Oxgp19ejZmU"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>genre</th>\n",
       "      <th>author</th>\n",
       "      <th>book</th>\n",
       "      <th>chapter</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>d</td>\n",
       "      <td>christie</td>\n",
       "      <td>secretadversary</td>\n",
       "      <td>23</td>\n",
       "      <td>. A RACE AGAINST TIME\\n\\nAFTER ringing up Sir ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>g</td>\n",
       "      <td>austen</td>\n",
       "      <td>northangerabbey</td>\n",
       "      <td>30</td>\n",
       "      <td>Catherine's disposition was not naturally sede...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>d</td>\n",
       "      <td>doyle</td>\n",
       "      <td>scarlet</td>\n",
       "      <td>5</td>\n",
       "      <td>. OUR ADVERTISEMENT BRINGS A VISITOR.\\n\\n\\nOUR...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>g</td>\n",
       "      <td>shelley</td>\n",
       "      <td>frankenstein</td>\n",
       "      <td>37</td>\n",
       "      <td>It was on a dreary night of November that I be...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>d</td>\n",
       "      <td>collins</td>\n",
       "      <td>moonstone</td>\n",
       "      <td>86</td>\n",
       "      <td>Late that evening, I was surprised at my lodgi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  genre    author             book  chapter  \\\n",
       "0     d  christie  secretadversary       23   \n",
       "1     g    austen  northangerabbey       30   \n",
       "2     d     doyle          scarlet        5   \n",
       "3     g   shelley     frankenstein       37   \n",
       "4     d   collins        moonstone       86   \n",
       "\n",
       "                                                text  \n",
       "0  . A RACE AGAINST TIME\\n\\nAFTER ringing up Sir ...  \n",
       "1  Catherine's disposition was not naturally sede...  \n",
       "2  . OUR ADVERTISEMENT BRINGS A VISITOR.\\n\\n\\nOUR...  \n",
       "3  It was on a dreary night of November that I be...  \n",
       "4  Late that evening, I was surprised at my lodgi...  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "T.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2Oxgp19ejZmU"
   },
   "source": [
    "## Set OHCO Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2Oxgp19ejZmU"
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    T = T.set_index(CHAPS)\n",
    "    T = T.sort_index()\n",
    "except KeyError:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2Oxgp19ejZmU"
   },
   "source": [
    "## Create stopwords list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2Oxgp19ejZmU"
   },
   "outputs": [],
   "source": [
    "sw = nltk.corpus.stopwords.words('english') + extra_stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2Oxgp19ejZmU"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\"]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sw[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ScU67cbRdqoE",
    "toc-hr-collapsed": true
   },
   "source": [
    "## Fix some characters to improve tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ScU67cbRdqoE"
   },
   "outputs": [],
   "source": [
    "T.text = T.text.str.replace(r\"(—|-)\", ' \\g<1> ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EcffE_kleR0f"
   },
   "source": [
    "## Chapters to Paragraphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EcffE_kleR0f"
   },
   "outputs": [],
   "source": [
    "paras = T.text.str.split(para_pat, expand=True)\\\n",
    "    .stack()\\\n",
    "    .to_frame()\\\n",
    "    .rename(columns={0:'para_str'})\n",
    "paras.index.names = PARAS\n",
    "paras.para_str = paras.para_str.str.strip()\n",
    "paras.para_str = paras.para_str.str.replace(r'\\n', ' ')\n",
    "paras.para_str = paras.para_str.str.replace(r'\\s+', ' ')\n",
    "paras = paras[~paras.para_str.str.match(r'^\\s*$')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ATUd7_HdeXk5"
   },
   "source": [
    "## Paragraphs to Sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ATUd7_HdeXk5"
   },
   "outputs": [],
   "source": [
    "sents = paras.para_str\\\n",
    "    .apply(lambda x: pd.Series(nltk.sent_tokenize(x)))\\\n",
    "    .stack()\\\n",
    "    .to_frame()\\\n",
    "    .rename(columns={0:'sent_str'})\n",
    "sents.index.names = SENTS\n",
    "del(paras)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JglgExtWeaqN"
   },
   "source": [
    "## Sentences to Tokens with POS tagging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JglgExtWeaqN"
   },
   "source": [
    "We create our own tokenizer to preserve whitespace."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JglgExtWeaqN"
   },
   "outputs": [],
   "source": [
    "tokenizer = RegexpTokenizer('\\s+', gaps=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JglgExtWeaqN"
   },
   "outputs": [],
   "source": [
    "# tokens = sents.sent_str\\\n",
    "#     .apply(lambda x: pd.Series(nltk.pos_tag(nltk.word_tokenize(x))))\\\n",
    "tokens = sents.sent_str\\\n",
    "    .apply(lambda x: pd.Series(nltk.pos_tag(tokenizer.tokenize(x))))\\\n",
    "    .stack()\\\n",
    "    .to_frame()\\\n",
    "    .rename(columns={0:'pos_tuple'})\n",
    "tokens.index.names = OHCO\n",
    "tokens['pos'] = tokens.pos_tuple.apply(lambda x: x[1])\n",
    "tokens['token_str'] = tokens.pos_tuple.apply(lambda x: x[0])\n",
    "tokens = tokens.drop('pos_tuple', 1)\n",
    "del(sents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wZT8DGE7ek4F"
   },
   "source": [
    "## Tag punctuation and numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wZT8DGE7ek4F"
   },
   "outputs": [],
   "source": [
    "tokens['punc'] = tokens.token_str.str.match(r'^[\\W_]*$').astype('int')\n",
    "tokens['num'] = tokens.token_str.str.match(r'^.*\\d.*$').astype('int')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "aH2pV_ABrkmB"
   },
   "source": [
    "## Extract vocab with minimal normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "aH2pV_ABrkmB"
   },
   "outputs": [],
   "source": [
    "WORDS = (tokens.punc == 0) & (tokens.num == 0)\n",
    "tokens.loc[WORDS, 'term_str'] = tokens.token_str.str.lower()\\\n",
    "    .str.replace(token_pat, '')\n",
    "#     .str.replace(r'[\"_*.\\']', '')\n",
    "vocab = tokens[tokens.punc == 0].term_str.value_counts().to_frame()\\\n",
    "    .reset_index()\\\n",
    "    .rename(columns={'index':'term_str', 'term_str':'n'})\n",
    "vocab = vocab.sort_values('term_str').reset_index(drop=True)\n",
    "vocab.index.name = 'term_id'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tKyrqpzfr7Le"
   },
   "source": [
    "## Get priors for Vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tKyrqpzfr7Le"
   },
   "outputs": [],
   "source": [
    "vocab['p'] = vocab.n / vocab.n.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "M9L8f3mBr8vW"
   },
   "source": [
    "## Add stems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "M9L8f3mBr8vW"
   },
   "outputs": [],
   "source": [
    "stemmer = nltk.stem.porter.PorterStemmer()\n",
    "vocab['port_stem'] = vocab.term_str.apply(lambda x: stemmer.stem(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "W6Lyvd5Qr93-"
   },
   "source": [
    "## Define stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "W6Lyvd5Qr93-"
   },
   "outputs": [],
   "source": [
    "stopwords = set(nltk.corpus.stopwords.words('english') + extra_stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "W6Lyvd5Qr93-"
   },
   "outputs": [],
   "source": [
    "sw = pd.DataFrame({'x':1}, index=stopwords)\n",
    "vocab['stop'] = vocab.term_str.map(sw.x).fillna(0).astype('int')\n",
    "del(sw)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WxRILKRNr-7C"
   },
   "source": [
    "## Add term_ids to Tokens "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WxRILKRNr-7C"
   },
   "outputs": [],
   "source": [
    "tokens['term_id'] = tokens['term_str'].map(vocab.reset_index()\\\n",
    "    .set_index('term_str').term_id).fillna(-1).astype('int')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NTWfAutZKuRP",
    "toc-hr-collapsed": true
   },
   "source": [
    "# Save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xLQ1KGZCsMFx"
   },
   "outputs": [],
   "source": [
    "with sqlite3.connect(db_file) as db:\n",
    "    T.to_sql('doc', db, if_exists='replace', index=True)\n",
    "    tokens.to_sql('token', db, if_exists='replace', index=True)\n",
    "    vocab.to_sql('vocab', db, if_exists='replace', index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4q1kGXJuLDSp"
   },
   "outputs": [],
   "source": [
    "# END"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "TextmanCorpusImporter.ipynb",
   "provenance": [
    {
     "file_id": "1UJXtZFtWykmkbZSLyLxpKmwiGhXr1w6P",
     "timestamp": 1550255827012
    }
   ],
   "toc_visible": true,
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
